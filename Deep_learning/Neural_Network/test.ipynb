{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    " \n",
    "class ANN:\n",
    "    def __init__(self, layers_size):\n",
    "        self.layers_size = layers_size\n",
    "        self.parameters = {}\n",
    "        self.L = len(self.layers_size)\n",
    "        self.n = 0\n",
    "        self.costs = []\n",
    " \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    " \n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z))\n",
    "        return expZ / expZ.sum(axis=0, keepdims=True)\n",
    " \n",
    "    def initialize_parameters(self):\n",
    "        np.random.seed(1)\n",
    " \n",
    "        for l in range(1, len(self.layers_size)):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], self.layers_size[l - 1]) / np.sqrt(\n",
    "                self.layers_size[l - 1])\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n",
    " \n",
    "    def forward(self, X):\n",
    "        store = {}\n",
    " \n",
    "        A = X.T\n",
    "        for l in range(self.L - 1):\n",
    "            Z = self.parameters[\"W\" + str(l + 1)].dot(A) + self.parameters[\"b\" + str(l + 1)]\n",
    "            A = self.sigmoid(Z)\n",
    "            store[\"A\" + str(l + 1)] = A\n",
    "            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n",
    "            store[\"Z\" + str(l + 1)] = Z\n",
    " \n",
    "        Z = self.parameters[\"W\" + str(self.L)].dot(A) + self.parameters[\"b\" + str(self.L)]\n",
    "        A = self.softmax(Z)\n",
    "        store[\"A\" + str(self.L)] = A\n",
    "        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n",
    "        store[\"Z\" + str(self.L)] = Z\n",
    " \n",
    "        return A, store\n",
    " \n",
    "    def sigmoid_derivative(self, Z):\n",
    "        s = 1 / (1 + np.exp(-Z))\n",
    "        return s * (1 - s)\n",
    " \n",
    "    def backward(self, X, Y, store):\n",
    " \n",
    "        derivatives = {}\n",
    " \n",
    "        store[\"A0\"] = X.T\n",
    " \n",
    "        A = store[\"A\" + str(self.L)]\n",
    "        dZ = A - Y.T\n",
    " \n",
    "        dW = dZ.dot(store[\"A\" + str(self.L - 1)].T) / self.n\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / self.n\n",
    "        dAPrev = store[\"W\" + str(self.L)].T.dot(dZ)\n",
    " \n",
    "        derivatives[\"dW\" + str(self.L)] = dW\n",
    "        derivatives[\"db\" + str(self.L)] = db\n",
    " \n",
    "        for l in range(self.L - 1, 0, -1):\n",
    "            dZ = dAPrev * self.sigmoid_derivative(store[\"Z\" + str(l)])\n",
    "            dW = 1. / self.n * dZ.dot(store[\"A\" + str(l - 1)].T)\n",
    "            db = 1. / self.n * np.sum(dZ, axis=1, keepdims=True)\n",
    "            if l > 1:\n",
    "                dAPrev = store[\"W\" + str(l)].T.dot(dZ)\n",
    " \n",
    "            derivatives[\"dW\" + str(l)] = dW\n",
    "            derivatives[\"db\" + str(l)] = db\n",
    " \n",
    "        return derivatives\n",
    " \n",
    "    def fit(self, X, Y, learning_rate=0.01, n_iterations=2500):\n",
    "        np.random.seed(1)\n",
    " \n",
    "        self.n = X.shape[0]\n",
    " \n",
    "        self.layers_size.insert(0, X.shape[1])\n",
    " \n",
    "        self.initialize_parameters()\n",
    "        for loop in range(n_iterations):\n",
    "            A, store = self.forward(X)\n",
    "            cost = -np.mean(Y * np.log(A.T+ 1e-8))\n",
    "            derivatives = self.backward(X, Y, store)\n",
    " \n",
    "            for l in range(1, self.L + 1):\n",
    "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\n",
    "                    \"dW\" + str(l)]\n",
    "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\n",
    "                    \"db\" + str(l)]\n",
    " \n",
    "            if loop % 100 == 0:\n",
    "                print(\"Cost: \", cost, \"Train Accuracy:\", self.predict(X, Y))\n",
    " \n",
    "            if loop % 10 == 0:\n",
    "                self.costs.append(cost)\n",
    " \n",
    "    def predict(self, X, Y):\n",
    "        A, cache = self.forward(X)\n",
    "        y_hat = np.argmax(A, axis=0)\n",
    "        Y = np.argmax(Y, axis=1)\n",
    "        accuracy = (y_hat == Y).mean()\n",
    "        return accuracy * 100\n",
    " \n",
    "    def plot_cost(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(self.costs)), self.costs)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.show()\n",
    " \n",
    " \n",
    "def pre_process_data(train_x, train_y, test_x, test_y):\n",
    "    # Normalize\n",
    "    train_x = train_x / 255.\n",
    "    test_x = test_x / 255.\n",
    " \n",
    "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "    train_y = enc.fit_transform(train_y.reshape(len(train_y), -1))\n",
    " \n",
    "    test_y = enc.transform(test_y.reshape(len(test_y), -1))\n",
    " \n",
    "    return train_x, train_y, test_x, test_y\n",
    " \n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "train_x, train_y, test_x, test_y = pre_process_data(train_x, train_y, test_x, test_y)\n",
    "\n",
    "print(\"train_x's shape: \" + str(train_x.shape))\n",
    "print(\"test_x's shape: \" + str(test_x.shape))\n",
    "\n",
    "layers_dims = [784,16,16, 10]\n",
    "\n",
    "ann = ANN(layers_dims)\n",
    "ann.fit(train_x[10], train_y[10], learning_rate=0.1, n_iterations=100)\n",
    "print(\"Train Accuracy:\", ann.predict(train_x, train_y))\n",
    "print(\"Test Accuracy:\", ann.predict(test_x, test_y))\n",
    "ann.plot_cost()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T06:38:10.182887200Z",
     "start_time": "2023-08-26T06:38:10.182887200Z"
    }
   },
   "id": "99853559f40ba390"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T06:39:19.554858Z",
     "start_time": "2023-08-26T06:39:19.530059300Z"
    }
   },
   "id": "2c2c1eb73404ebd2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:31:56.117626300Z",
     "start_time": "2023-09-21T07:31:55.975167600Z"
    }
   },
   "id": "b1c136f9744d8c2f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "W_1 = np.random.randint(-10, 10,(2, 2))\n",
    "W_2 = np.random.randint(-10,10, (2, 1))\n",
    "b_1 = np.random.randint(-10,10, (1, 2))\n",
    "b_2 = np.random.randint(-10,10, (1, 1))\n",
    "x_1 = np.random.randint(-10,10, (1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:35:03.581999600Z",
     "start_time": "2023-09-21T07:35:03.554232900Z"
    }
   },
   "id": "81618c2a1f99ce05"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "x_2 = x_1@W_1 +b_1\n",
    "a_2 = np.tanh(x_2)\n",
    "x_3 = a_2@W_2 + b_2\n",
    "y_pred = np.tanh(x_3)\n",
    "y = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:44:03.833714700Z",
     "start_time": "2023-09-21T07:44:03.806179100Z"
    }
   },
   "id": "a4370f84b01001b7"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.00000000e+00, -1.19070628e-09],\n       [ 0.00000000e+00, -2.38141256e-09]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1.T@(y-y_pred)*(1-np.tanh(y_pred)**2)*W_2.T*(1-a_2**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:45:58.676690700Z",
     "start_time": "2023-09-21T07:45:58.645727500Z"
    }
   },
   "id": "ce4c67a662e9e854"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.19070628e-09]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y-y_pred)*(1-np.tanh(y_pred)**2)*W_2[1,0]*(1-a_2[0,1]**2)*x_1[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:55:45.252484400Z",
     "start_time": "2023-09-21T07:55:45.223512900Z"
    }
   },
   "id": "c3f8fac1ae21938d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-7],\n       [ 2]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T07:54:52.603417500Z",
     "start_time": "2023-09-21T07:54:52.584247700Z"
    }
   },
   "id": "b8262a4f2b9ed607"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "41d58a31ecb8c97b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
